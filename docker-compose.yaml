services:
  caddy:
    container_name: caddy
    image: docker.io/library/caddy:2-alpine
    network_mode: host
    restart: unless-stopped
    volumes:
      - ./searxng/Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy-data:/data:rw
      - caddy-config:/config:rw
    environment:
      - SEARXNG_HOSTNAME=${SEARXNG_HOSTNAME:-http://localhost:80}
      - SEARXNG_TLS=${LETSENCRYPT_EMAIL:-internal}
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    logging:
        driver: "json-file"
        options:
          max-size: "1m"
          max-file: "1"

  redis:
    container_name: redis
    image: docker.io/valkey/valkey:8-alpine
    command: valkey-server --save 30 1 --loglevel warning
    restart: unless-stopped
    networks:
      - searxng
    volumes:
      - valkey-data2:/data
    cap_drop:
      - ALL
    cap_add:
      - SETGID
      - SETUID
      - DAC_OVERRIDE
    logging:
        driver: "json-file"
        options:
          max-size: "1m"
          max-file: "1"

  searxng:
    container_name: searxng
    image: docker.io/searxng/searxng:latest
    restart: unless-stopped
    networks:
      - searxng
    ports:
      - "127.0.0.1:8888:8080"
    volumes:
      - ./searxng:/etc/searxng:rw
    environment:
      - SEARXNG_BASE_URL=https://${SEARXNG_HOSTNAME:-localhost}/
      - UWSGI_WORKERS=${SEARXNG_UWSGI_WORKERS:-4}
      - UWSGI_THREADS=${SEARXNG_UWSGI_THREADS:-4}
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    logging:
        driver: "json-file"
        options:
          max-size: "1m"
          max-file: "1"

  mongodb:
    container_name: mongodb
    image: mongo:latest
    restart: unless-stopped
    ports:
      - "127.0.0.1:27018:27017"
    volumes:
      - mongodb-data:/data/db
    environment:
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_ROOT_USERNAME:-root}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_ROOT_PASSWORD:-example}
    logging:
        driver: "json-file"
        options:
          max-size: "1m"
          max-file: "1"

  qdrant:
    container_name: qdrant
    image: qdrant/qdrant:latest
    network_mode: host
    restart: unless-stopped
    ports:
      - "6333:6333" 
    environment:
      - RUN_MODE=production
      - QDRANT__GPU__INDEXING=1 
    logging:
        driver: "json-file"
        options:
          max-size: "1m"
          max-file: "1"
  ollama-server:
    image: ollama/ollama:latest
    volumes:
      - type: bind
        source: /usr/share/ollama/.ollama/models
        target: /app/ollama/models
    environment:
      OLLAMA_MODELS: /app/ollama/models
      OLLAMA_HOST: 0.0.0.0
    ports:
      - "11000:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    command: serve && pull deepseek-r1:7b
networks:
  searxng:

volumes:
  caddy-data:
  caddy-config:
  valkey-data2:
  mongodb-data:
